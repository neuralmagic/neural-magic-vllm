{
	"configs": [
		{
			"description": "Benchmark vllm engine prefill throughput - synthetic - Dense",
			"models": [
                          "teknium/OpenHermes-2.5-Mistral-7B",
                          "neuralmagic/OpenHermes-2.5-Mistral-7B-marlin",
                          "TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ",
                          "NousResearch/Llama-2-7b-chat-hf"
			],
			"max_model_lens" : [4096],
			"script_name": "benchmark_throughput",
			"script_args": {
				"input-len": [
					16,
					32,
					64,
					128,
					256,
					512,
					1024,
                                        2048
				],
				"output-len": [
					1
				],
				"num-prompts": [
					1
				],
				"use-all-available-gpus_" : []
			}
		},
		{
			"description": "Benchmark vllm engine prefill throughput - synthetic - Sparse",
			"models": [
                          "neuralmagic/OpenHermes-2.5-Mistral-7B-pruned50"
			],
			"max_model_lens" : [4096],
			"script_name": "benchmark_throughput",
			"script_args": {
				"input-len": [
					16,
					32,
					64,
					128,
					256,
					512,
					1024,
                                        2048
				],
				"output-len": [
					1
				],
				"num-prompts": [
					1
				],
			        "sparsity": ["sparse_w16a16"],
				"use-all-available-gpus_" : []
			}
		},
		{
			"description": "Benchmark vllm engine prefill throughput - synthetic - 2:4 Sparse",
			"models": [
                          "neuralmagic/OpenHermes-2.5-Mistral-7B-pruned2.4"
			],
			"max_model_lens" : [4096],
			"script_name": "benchmark_throughput",
			"script_args": {
				"input-len": [
					16,
					32,
					64,
					128,
					256,
					512,
					1024,
                                        2048
				],
				"output-len": [
					1
				],
				"num-prompts": [
					1
				],
			        "sparsity": ["semi_structured_sparse_w16a16"],
				"use-all-available-gpus_" : []
			}
		}
        ]
}

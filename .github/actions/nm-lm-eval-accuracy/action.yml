name: run lm-eval full accuracy test
description: 'run lm-eval full accuracy test'
inputs:
  python:
    description: 'python version, e.g. 3.10.12'
    required: true
  venv:
    description: 'name for python virtual environment'
    required: true
runs:
  using: composite
  steps:
  - id: lm-eval
    run: |
      COMMIT=${{ github.sha }}
      VENV="${{ inputs.venv }}-${COMMIT:0:7}"
      source $(pyenv root)/versions/${{ inputs.python }}/envs/${VENV}/bin/activate

      pip3 install git+https://github.com/EleutherAI/lm-evaluation-harness.git@262f879a06aa5de869e5dd951d0ff2cf2f9ba380[openai]

      SUCCESS=0
      python .github/scripts/test_lm_eval_sweep.py -s -v || SUCCESS=$?
      echo "test=${SUCCESS}" >> "$GITHUB_OUTPUT"
      exit ${SUCCESS}
    shell: bash

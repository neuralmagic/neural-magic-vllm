name: run lm-eval accuracy test
description: 'run lm-eval accuracy test'
inputs:
  python:
    description: 'python version, e.g. 3.10.12'
    required: true
  venv:
    description: 'name for python virtual environment'
    required: true
  lm_eval_configuration:
    description: 'file containing test configuration'
    required: true
runs:
  using: composite
  steps:
  - id: lm-eval
    run: |
      if [ -n "${{ inputs.venv }}" ]; then
        COMMIT=${{ github.sha }}
        VENV="${{ inputs.venv }}-${COMMIT:0:7}"
        source $(pyenv root)/versions/${{ inputs.python }}/envs/${VENV}/bin/activate
      fi

      pip3 install git+https://github.com/EleutherAI/lm-evaluation-harness.git@262f879a06aa5de869e5dd951d0ff2cf2f9ba380
      pip3 install pytest openai==1.3.9

      SUCCESS=0
      ./.github/scripts/nm-run-lm-eval-vllm.sh -c ${{ inputs.lm_eval_configuration }} || SUCCESS=$?
      echo "lm_eval=${SUCCESS}" >> "$GITHUB_OUTPUT"
      exit ${SUCCESS}
    shell: bash
